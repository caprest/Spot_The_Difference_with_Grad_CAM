import os
import subprocess

import cv2
import keras
import numpy as np
import tensorflow as tf
from keras import backend as K
from keras.callbacks import History
from keras.layers import Dense, Flatten, Dropout, Conv2D, BatchNormalization, Activation, MaxPooling2D
from keras.models import Sequential
from keras.preprocessing.image import ImageDataGenerator

# Download File
if not os.path.exists("body.jpg"):
    subprocess.call("wget https://www.saizeriya.co.jp/entertainment/images/italy/body.jpg", shell=True)


def get_model(input_shape):
    model = Sequential()
    model.add(Conv2D(32, (9, 9), input_shape=input_shape))
    model.add(Dropout(0.1))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.3))

    model.add(Conv2D(64, (3, 3)))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Conv2D(64, (3, 3)))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.2))

    model.add(Conv2D(64, (3, 3), name="conv3"))
    model.add(BatchNormalization())
    model.add(Activation('relu', name="acitvation"))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.2))

    model.add(Flatten())
    model.add(Dense(64))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(2))
    model.add(Activation('softmax'))
    model.compile(loss='categorical_crossentropy',
                  optimizer=keras.optimizers.Adam(lr=1e-3),
                  metrics=['accuracy'])
    return model


def random_mask(array, mask_size=120):
    height = array.shape[0]
    width = array.shape[1]
    x = np.random.randint(height - mask_size)
    y = np.random.randint(width - mask_size)
    new_array = np.zeros_like(array)
    new_array[x:x + mask_size, y:y + mask_size, :] = array[x:x + mask_size, y:y + mask_size, :]
    return new_array


def save_history(history, name="history.npy"):
    save_history = dict()
    for k, v in history.history.items():
        save_history[k] = v
    save_history["epoch"] = np.array(history.epoch)
    np.save("history.npy", save_history)


datagen = ImageDataGenerator()


def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y + dy), x:(x + dx), :]


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        rand = np.random.rand(batch_x.shape[0], crop_length, crop_length, 3) * 0.01
        for i in range(batch_x.shape[0]):
            batch_crops[i] = random_crop(batch_x[i], (crop_length, crop_length))
        batch_crops += rand
        yield (batch_crops, batch_y)


if __name__ == "__main__":
    # acquire gpu memory
    config = tf.ConfigProto(
        gpu_options=tf.GPUOptions(
            visible_device_list=str(0),  # specify GPU number
            allow_growth=True
        )
    )
    K.set_session(tf.Session(config=config))
    img = cv2.imread("body.jpg")[:, :, ::-1]
    img = cv2.GaussianBlur(img, (5, 5), 0)
    left = img[:, 33:590] / 255
    right = img[:, 602:602 + 590 - 33] / 255
    x_train = np.array([left, right] * 16)
    y_train = np.array([[1, 0], [0, 1]] * 16)
    checkpoint = keras.callbacks.ModelCheckpoint(
        filepath="weights/weights.{epoch:02d}-{loss:.2f}.hdf5",
        monitor='loss',
        verbose=0,
        save_best_only=False,
        save_weights_only=True,
        mode='auto',
        period=200)
    history = History()
    datagen = ImageDataGenerator()
    generator = crop_generator(datagen.flow(x_train, y_train, batch_size=16), 180)
    model = get_model((180, 180, 3))
    model.fit_generator(generator,
                        steps_per_epoch=10, epochs=1000, callbacks=[checkpoint, history])
    model.save("model.h5")
    save_history(history)
